---
title: "Ajuste de regressão logística - Trabalho 2"
subtitle: Por Adílio Vitor de Oliveira Júnior e Lucas Santos Bicalho
output:
  pdf_document: default
  html_document:
    df_print: paged
---


# 1. Contexto dos dados

Os dados estão disponíveis em https://archive.ics.uci.edu/ml/datasets/student+performance.
Objetivo é modelar uma regressão logística para os alunos da disciplina de matemática, no teste final G3.
A variável G3 foi recodificada em uma nova, chamada G3_final, onde se a nota obtida pelo aluno for maior que 10, então G3_Final recebe 1, caso contrário recebe 0.

# 2. Código fonte

O código abaixo foi obtido na nota de aula 20.

```{r message=FALSE, warning=FALSE}

library(tidyverse)
library(glmnet)
library(nnet)
library(caret)
library(ROCit)
library(e1071)

dados <- read.csv2("student-mat.csv", header = TRUE)

dados <- mutate(dados,
            G1_final = ifelse(G1 <= 10, 0, 1),
            G2_final =  ifelse(G2 <= 10, 0, 1),
            G3_final = ifelse(G3 <= 10, 0, 1)) %>% 
          select(-G1) %>% select(-G2) %>% select(-G3) 

names(dados)


set.seed(1)
dat_idx <- sample(nrow(dados), round(0.7*nrow(dados)))
dat_trn <- dados[dat_idx, ]
dat_tst <- dados[-dat_idx, ]


full.model <- glm(G3_final~ ., data = dat_trn, 
                 family="binomial")


backward.model = MASS::stepAIC(full.model,
                               scope = list(upper = ~.,  lower = ~1),
                               family="binomial",
                               direction="both", trace = FALSE)

summary(backward.model)

#Testing data
score2 <- predict(backward.model, type = "response", newdata = dat_tst) 
obs2 <- dat_tst$G3_final

ROCit_obj2 <- rocit(score=score2,class=obs2)


```


# 3. Interpretações

## 3.1 Curva ROC

```{r}
plot(ROCit_obj2)

```

  Como pudemos observar na curva ROC, o modelo desenvolvido apresentou valores altos de sensibilidade para baixos valores de especificidade. Como nossa intenção é modelar os alunos que serão aprovados (sensibilidade), esse modelo conseguiu uma boa performance. A *AUC* do modelo é de `r round(ROCit_obj2$AUC,4)*100`%, confirmando a boa indicativa de performance do modelo.

## 3.2 Cutoff

```{r}
optimal_cutoff = ROCit_obj2$Cutoff[which.max(ROCit_obj2$TPR - ROCit_obj2$FPR)]
```

Nós obtivemos um valor de *cutoff* ótimo de `r optimal_cutoff`, o que indica que a melhor acurácia do modelo foi obtida quando 55.81% das amostras eram de alunos que foram aprovados.
=
## 3.3 Matriz de Confusão

```{r}

model_glm_pred= ifelse(predict(backward.model, type = "response",newdata=dat_tst) > optimal_cutoff, "1", "0")
train_tab = table(predicted = model_glm_pred, actual = as.character(dat_tst$G3_final))
train_con_mat <- confusionMatrix(train_tab, positive = "1")
train_con_mat$table


```

Na matriz de confusão, podemos ver que o modelo obteve 55 verdadeiros positivos e 6 falsos positivos. Esse modelo também obteve 7 falsos negativos e 51 verdadeiros negativos.

## 3.4 Accuracy

Para esse modelo, nós obtivemos uma acurácia de `r train_con_mat$overall["Accuracy"]`, o que indica que o modelo predisse corretamente em 89.07% dos casos.

## 3.5 Overall

```{r, warning = FALSE, message = FALSE, echo=FALSE}
train_con_mat$byClass
```

Precision: É a relacação entre verdadeiros positivos e a soma de verdadeiros positivos com falsos positivos. Como obtivemos um valor de 0.9016, significa que em 90.16% das predições de positivo, o modelo predisse corretamente.

Recall: É a relação entre verdadeiros positivos e a soma de verdadeiros positivos com falsos negativos. Como obtivemos um valor de 0.88709, significa que o modelo "encontrou" os verdadeiros positivos e os predisse corretamente em 88.71% dos casos.

F1: Também conhecido como "valor harmônico", é uma média harmônica entre Precision e Recall. Quanto mais próximo de 1, melhor é o modelo, pois significa uma menor presença de falsos positivos e falsos negativos. No nosso modelo, obtivemos um F1 de 0.8943.